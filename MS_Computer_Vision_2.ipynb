{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICROSOFT COMPUTER VISION API - DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook please:\n",
    "\n",
    "1. Create a Cognitive Services resource using the Azure portal.\n",
    "\n",
    "2. Configure the environment variables for authentication:\n",
    "\n",
    "https://docs.microsoft.com/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Cunix#configure-an-environment-variable-for-authentication\n",
    "\n",
    "COMPUTER_VISION_SUBSCRIPTION_KEY\n",
    "COMPUTER_VISION_ENDPOINT\n",
    "\n",
    "\n",
    "................. for macOS\n",
    "\n",
    "export COMPUTER_VISION_SUBSCRIPTION_KEY=*********\n",
    "\n",
    "export COMPUTER_VISION_ENDPOINT=*********\n",
    "\n",
    "source .bash_profile\n",
    "\n",
    "\n",
    "\n",
    "-------------------------------\n",
    "Computer Vision API - v2.0 - documentation:\n",
    "\n",
    "https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa\n",
    "\n",
    "https://docs.microsoft.com/pl-pl/azure/cognitive-services/Computer-vision/quickstarts/python-hand-text\n",
    "\n",
    "\n",
    "WEB API: https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/\n",
    "\n",
    "\n",
    "DEMO: https://github.com/microsoft/Cognitive-Vision-Python/blob/master/Jupyter%20Notebook/Computer%20Vision%20API%20Example.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "#import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add subscription key and endpoint to your variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your Computer Vision subscription key and endpoint to your environment variables.\n",
    "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "    SUBSCRIPTION_KEY = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "\n",
    "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "    ENDPOINT = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SendRequestLocal(image_path, \n",
    "                     params = {'visualFeatures': 'Categories, Description, Color, Faces'},\n",
    "                     subscription_key = SUBSCRIPTION_KEY,\n",
    "                     endpoint = ENDPOINT):\n",
    "\n",
    "    #Read the image into a byte array\n",
    "    image_data = open(image_path, \"rb\").read()\n",
    "\n",
    "    \n",
    "    analyze_url = endpoint + \"vision/v2.0/analyze\"\n",
    "\n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "               'Content-Type': 'application/octet-stream'}\n",
    "\n",
    "    #params = {'visualFeatures': 'Categories, Description, Color, Faces'}\n",
    "\n",
    "    response = requests.post(analyze_url,\n",
    "                             headers=headers,\n",
    "                             params=params,\n",
    "                             data=image_data)\n",
    "\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    analysis = response.json()\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PlotImageLocal(image_path,\n",
    "                   figsize=(15, 20)):\n",
    "\n",
    "    \n",
    "    img = mpimg.imread(image_path)\n",
    "\n",
    "\n",
    "    ig, ax = plt.subplots(figsize=figsize)\n",
    "    fig = ax.imshow( img )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote image (from URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SendRequestUrl(image_url, \n",
    "                   params = {'visualFeatures': 'Categories, Description'},\n",
    "                   subscription_key = SUBSCRIPTION_KEY,\n",
    "                   endpoint = ENDPOINT):\n",
    "\n",
    "    \n",
    "    analyze_url = endpoint + \"vision/v2.0/analyze\"\n",
    "\n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "    response = requests.post(analyze_url,\n",
    "                             headers=headers,\n",
    "                             params=params,\n",
    "                             json={'url': image_url})\n",
    "\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    analysis = response.json()\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PlotImageUrl(image_url,\n",
    "                 figsize=(15, 20)):\n",
    "    \n",
    "    image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "    \n",
    "    ig, ax = plt.subplots(figsize=figsize)\n",
    "    fig = ax.imshow( image )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SendRequestOCRUrl(image_url, \n",
    "                     subscription_key = SUBSCRIPTION_KEY,\n",
    "                     endpoint = ENDPOINT):\n",
    "\n",
    "    text_url = endpoint + \"vision/v2.0/read/core/asyncBatchAnalyze\"\n",
    "\n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "    data = {'url': image_url}\n",
    "    \n",
    "    response = requests.post(text_url,\n",
    "                             headers=headers,\n",
    "                             json=data)\n",
    "\n",
    "    response.raise_for_status()\n",
    "    \n",
    "\n",
    "\n",
    "    # Extracting text requires two API calls: One call to submit the\n",
    "    # image for processing, the other to retrieve the text found in the image.\n",
    "\n",
    "    # Holds the URI used to retrieve the recognized text.\n",
    "    operation_url = response.headers[\"Operation-Location\"]\n",
    "\n",
    "    # The recognized text isn't immediately available, so poll to wait for completion.\n",
    "    analysis = {}\n",
    "    poll = True\n",
    "    while (poll):\n",
    "        response_final = requests.get(\n",
    "            response.headers[\"Operation-Location\"], headers=headers)\n",
    "        analysis = response_final.json()\n",
    "        print(analysis)\n",
    "        time.sleep(1)\n",
    "        if (\"recognitionResults\" in analysis):\n",
    "            poll = False\n",
    "        if (\"status\" in analysis and analysis['status'] == 'Failed'):\n",
    "            poll = False\n",
    "    \n",
    "    return analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print rectangles and descriptions\n",
    "\n",
    "def PrintRectFace(rectangles,\n",
    "                    fig,\n",
    "                    color=\"fuchsia\",\n",
    "                    linewidth=2):\n",
    "    for face in rectangles:\n",
    "        rec = plt.Rectangle(xy=(face[\"faceRectangle\"][\"left\"], face[\"faceRectangle\"][\"top\"]),\n",
    "            width=face[\"faceRectangle\"][\"width\"], height=face[\"faceRectangle\"][\"height\"],\n",
    "                fill=False, edgecolor=color, linewidth=linewidth)\n",
    "\n",
    "        fig.axes.add_patch(rec)\n",
    "        print (face)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PrintRectObject(rectangles,\n",
    "                    fig,\n",
    "                    color=\"fuchsia\",\n",
    "                    linewidth=2):\n",
    "    for obj in rectangles:\n",
    "        rec = plt.Rectangle(xy=(obj[\"rectangle\"][\"x\"], obj[\"rectangle\"][\"y\"]),\n",
    "            width=obj[\"rectangle\"][\"w\"], height=obj[\"rectangle\"][\"h\"],\n",
    "                fill=False, edgecolor=color, linewidth=linewidth)\n",
    "\n",
    "        fig.axes.add_patch(rec)\n",
    "        print (obj)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE & CELEBRITY DETECTION - local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  Set image_path to the local path of an image that you want to analyze.\n",
    "image_path = \"/Users/doma022/Desktop/AI_Workshop/T_Rabe2.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestLocal(image_path,\n",
    "                            params = {'visualFeatures': 'Categories, Description, Faces',\n",
    "                                      'details': 'Celebrities'})\n",
    "\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "## Sort faces from left to right\n",
    "sorted_faces = sorted(analysis[\"faces\"], key=lambda k: k['faceRectangle'][\"left\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectFace(sorted_faces, fig)\n",
    "\n",
    "#print(analysis)\n",
    "#print(analysis[\"description\"][\"captions\"])\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CELEBRITY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "## Sort faces from left to right\n",
    "sorted_celeb= sorted(analysis[\"categories\"][0][\"detail\"][\"celebrities\"],\n",
    "                     key=lambda k: k['faceRectangle'][\"left\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectFace(sorted_celeb, fig, color='red')\n",
    "\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis[\"description\"][\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Set image_path to the local path of an image that you want to analyze.\n",
    "image_path = \"/Users/doma022/Desktop/AI_Workshop/_DSC7162.jpg\"\n",
    "\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestLocal(image_path,\n",
    "                            params = {'visualFeatures': 'Categories, Description, Faces',\n",
    "                                      'details': 'Celebrities'})\n",
    "\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "\n",
    "print(\"FACES:\")\n",
    "\n",
    "## Sort faces from left to right\n",
    "sorted_faces = sorted(analysis[\"faces\"], key=lambda k: k['faceRectangle'][\"left\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectFace(sorted_faces, fig, color=\"yellow\")\n",
    "\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis[\"description\"][\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTS - remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cologne\n",
    "image_path = \"/Users/doma022/Desktop/AI_Workshop/_DSC6786.jpg\"\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestLocal(image_path,\n",
    "                            params = {'visualFeatures': 'Categories, Description, Objects'})\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "\n",
    "print(\"OBJECTS:\")\n",
    "## Sort faces from left to right\n",
    "sorted_obj = sorted(analysis[\"objects\"], key=lambda k: k['rectangle'][\"x\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectObject(sorted_obj, fig)\n",
    "\n",
    "\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis[\"description\"][\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRH\n",
    "image_path = \"https://i.ytimg.com/vi/T3kXO_SzeTQ/maxresdefault.jpg\"\n",
    "\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestUrl(image_path,\n",
    "                          params = {'visualFeatures': 'Categories, Description, Objects, Faces',\n",
    "                                    'details': 'Celebrities'})\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageUrl(image_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"OBJECTS:\")\n",
    "\n",
    "## Sort faces from left to right\n",
    "sorted_obj = sorted(analysis[\"objects\"], key=lambda k: k['rectangle'][\"x\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectObject(sorted_obj, fig)\n",
    "\n",
    "\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brands\n",
    "image_path = \"/Users/doma022/Desktop/AI_Workshop/brands.jpg\"\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestLocal(image_path,\n",
    "                            params = {'visualFeatures': 'Categories, Description, Objects, Brands'})\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cologne\n",
    "image_path = \"/Users/doma022/Desktop/AI_Workshop/reebook.jpg\"\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestLocal(image_path,\n",
    "                            params = {'visualFeatures': 'Categories, Description, Objects, Brands'})\n",
    "\n",
    "\n",
    "## Print the image and the API response\n",
    "\n",
    "fig = PlotImageLocal(image_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"OBJECTS:\")\n",
    "## Sort faces from left to right\n",
    "sorted_obj = sorted(analysis[\"objects\"], key=lambda k: k['rectangle'][\"x\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectObject(sorted_obj, fig)\n",
    "\n",
    "\n",
    "print(\"======\")\n",
    "print(\"BRANDS:\")\n",
    "## Sort faces from left to right\n",
    "sorted_brands = sorted(analysis[\"brands\"], key=lambda k: k['rectangle'][\"x\"]) \n",
    "\n",
    "## Print rectangles and descriptions\n",
    "PrintRectObject(sorted_brands, fig, color=\"blue\")\n",
    "\n",
    "\n",
    "#print(analysis)\n",
    "#print(analysis[\"description\"][\"captions\"])\n",
    "\n",
    "print(\"======\")\n",
    "print(\"CAPTION:\")\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR (optical character recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = \"/Users/doma022/Desktop/AI_Workshop/OCR.jpg\"\n",
    "image_path = \"https://media.npr.org/assets/img/2016/04/17/handwritten-note_wide-941ca37f3638dca912c8b9efda05ee9fefbf3147.jpg\"\n",
    "\n",
    "# Display the image and overlay it with the extracted text.\n",
    "fig = PlotImageUrl(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"https://media.npr.org/assets/img/2016/04/17/handwritten-note_wide-941ca37f3638dca912c8b9efda05ee9fefbf3147.jpg\"\n",
    "\n",
    "\n",
    "# Send request to the CV API\n",
    "analysis = SendRequestOCRUrl(image_path)\n",
    "\n",
    "\n",
    "# Display the image and overlay it with the extracted text.\n",
    "fig = PlotImageUrl(image_path)\n",
    "\n",
    "\n",
    "\n",
    "polygons = []\n",
    "if (\"recognitionResults\" in analysis):\n",
    "    # Extract the recognized text, with bounding boxes.\n",
    "    polygons = [(line[\"boundingBox\"], line[\"text\"])\n",
    "                for line in analysis[\"recognitionResults\"][0][\"lines\"]]\n",
    "\n",
    "    \n",
    "for polygon in polygons:\n",
    "    vertices = [(polygon[0][i], polygon[0][i+1])\n",
    "                for i in range(0, len(polygon[0]), 2)]\n",
    "    text = polygon[1]\n",
    "    patch = Polygon(vertices, closed=True, fill=False, linewidth=2, color='y')\n",
    "    fig.axes.add_patch(patch)\n",
    "    plt.text(vertices[0][0], vertices[0][1], text, fontsize=20, va=\"top\", color='red')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
